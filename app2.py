# -*- coding: utf-8 -*-
"""app2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ru0YDtT2XmaU3aGBXgLzFXH0w5y-YVXk
"""

# app.py
import os
import tempfile
from typing import Optional, Tuple
import requests
import streamlit as st
import pandas as pd
import joblib

st.set_page_config(page_title="é¢¨éšªåˆ†æ•¸é æ¸¬å™¨ï¼ˆCox æ¨¡å‹ï¼‰", layout="centered")

# -------------------------
# Default GitHub blob links (you provided)
# -------------------------
DEFAULT_MODEL_BLOB = "https://github.com/faifaiwong/survival/blob/main/model.h5"
DEFAULT_PREPROC_BLOB = "https://github.com/faifaiwong/survival/blob/main/preprocessor.pkl"

# -------------------------
# Feature / UI è¨­å®š
# -------------------------
continuous_vars = ['age', 'ca199', 'size']
categorical_vars = ['sex', 'grade', 'margin', 'LVI', 'PNI', 'pT', 'pN',
                    'cysticneoplasm', 'neoadjuvant', 'opmethod']
all_model_features = continuous_vars + categorical_vars

sex_opts = ["M", "F"]
grade_opts = ["G1", "G2", "G3"]
yn_opts = ["0", "1", "No", "Yes"]
pT_opts = ["T1", "T2", "T3", "T4"]
pN_opts = ["N0", "N1", "N2", "N3"]
op_opts = ["Open", "Lap", "Robot", "Other"]

# -------------------------
# helper utilities
# -------------------------
def _write_bytes_to_tempfile(b: bytes, suffix: str) -> str:
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    try:
        tmp.write(b)
        tmp.flush()
        return tmp.name
    finally:
        tmp.close()

def download_url_to_bytes(url: str, headers: Optional[dict] = None, timeout: int = 60) -> bytes:
    resp = requests.get(url, headers=headers, stream=True, timeout=timeout)
    resp.raise_for_status()
    return resp.content

def convert_github_blob_to_raw(url: str) -> str:
    """
    Convert a GitHub 'blob' URL to raw.githubusercontent.com URL.
    If url is not a github blob URL, return it unchanged.
    """
    if not url:
        return url
    if "github.com" in url and "/blob/" in url:
        return url.replace("https://github.com/", "https://raw.githubusercontent.com/").replace("/blob/", "/")
    return url

def get_github_asset_browser_download_url(repo: str, asset_name: str, token: Optional[str] = None) -> str:
    """
    repo: 'owner/repo'
    asset_name: exact filename in release assets (e.g. model.h5)
    returns browser_download_url
    """
    api = f"https://api.github.com/repos/{repo}/releases/latest"
    headers = {}
    if token:
        headers["Authorization"] = f"token {token}"
    r = requests.get(api, headers=headers, timeout=20)
    r.raise_for_status()
    rel = r.json()
    assets = rel.get("assets", []) or []
    for a in assets:
        if a.get("name") == asset_name:
            return a.get("browser_download_url")
    raise FileNotFoundError(f"Asset '{asset_name}' not found in latest release of {repo}.")

# -------------------------
# custom loss (lazy import tensorflow inside)
# -------------------------
def cox_ph_loss(y_true, y_pred):
    import tensorflow as tf  # lazy import
    events = tf.cast(y_true[:, 0], tf.float32)
    times = tf.cast(y_true[:, 1], tf.float32)
    risk = tf.squeeze(y_pred, axis=-1)

    order = tf.argsort(times, direction='DESCENDING')
    risk_ordered = tf.gather(risk, order)
    event_ordered = tf.gather(events, order)

    shift = tf.reduce_max(risk_ordered)
    exp_risk_shifted = tf.exp(risk_ordered - shift)

    cumsum_exp = tf.cumsum(exp_risk_shifted)
    log_cumsum_exp = tf.math.log(cumsum_exp) + shift

    log_lik = risk_ordered - log_cumsum_exp
    log_lik_event = tf.boolean_mask(log_lik, event_ordered > 0)
    neg_mean_log_lik = -tf.reduce_mean(log_lik_event)
    return neg_mean_log_lik

# -------------------------
# Loaders (cached)
# -------------------------
@st.cache_resource
def load_resources_from_urls(model_url: str, preproc_url: str, token: Optional[str] = None) -> Tuple[Optional[object], Optional[object], str]:
    """
    Download model & preproc from URLs and load them.
    Returns (model, preproc, message)
    """
    model_path = None
    preproc_path = None
    try:
        headers = {"Authorization": f"token {token}"} if token else None

        model_bytes = download_url_to_bytes(model_url, headers=headers)
        preproc_bytes = download_url_to_bytes(preproc_url, headers=headers)

        model_path = _write_bytes_to_tempfile(model_bytes, suffix=".h5")
        preproc_path = _write_bytes_to_tempfile(preproc_bytes, suffix=".pkl")

        # lazy import tensorflow & load model
        try:
            import tensorflow as tf  # lazy
            from tensorflow.keras.models import load_model
        except Exception as e:
            return None, None, f"âŒ ç„¡æ³• import TensorFlowï¼š{e}. è‹¥è¦åœ¨æ­¤ç’°å¢ƒè¼‰å…¥æ¨¡å‹ï¼Œè«‹åœ¨ requirements.txt æŒ‡å®šåˆé©çš„ tensorflow-cpu ç‰ˆæœ¬ã€‚"

        model = load_model(model_path, custom_objects={'cox_ph_loss': cox_ph_loss})

        try:
            preproc = joblib.load(preproc_path)
        except ModuleNotFoundError as e:
            missing = str(e).split("'")[1] if "'" in str(e) else str(e)
            return None, None, f"âŒ è¼‰å…¥ preprocessor å¤±æ•—ï¼šç¼ºå°‘æ¨¡çµ„ {missing}ã€‚è«‹åœ¨ requirements.txt åŠ å…¥è©²å¥—ä»¶ï¼ˆä¾‹å¦‚ dillï¼‰ï¼Œä¸¦é‡æ–°éƒ¨ç½²ã€‚"
        except Exception as e:
            return None, None, f"âŒ è¼‰å…¥ preprocessor ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"

        return model, preproc, "âœ… æ¨¡å‹èˆ‡ Preprocessor è¼‰å…¥æˆåŠŸ (from URLs)"
    except Exception as e:
        return None, None, f"âŒ ä¸‹è¼‰æˆ–è¼‰å…¥å¤±æ•—ï¼š{e}"
    finally:
        for p in (model_path, preproc_path):
            try:
                if p and os.path.exists(p):
                    os.remove(p)
            except Exception:
                pass

@st.cache_resource
def load_resources_from_bytes_local(model_bytes: bytes, preproc_bytes: bytes) -> Tuple[Optional[object], Optional[object], str]:
    """
    Load model & preproc from provided bytes (uploaded files).
    """
    model_path = None
    preproc_path = None
    try:
        model_path = _write_bytes_to_tempfile(model_bytes, suffix=".h5")
        preproc_path = _write_bytes_to_tempfile(preproc_bytes, suffix=".pkl")

        try:
            import tensorflow as tf
            from tensorflow.keras.models import load_model
        except Exception as e:
            return None, None, f"âŒ ç„¡æ³• import TensorFlowï¼š{e}. è‹¥è¦åœ¨æ­¤ç’°å¢ƒè¼‰å…¥æ¨¡å‹ï¼Œè«‹åœ¨ requirements.txt æŒ‡å®šåˆé©çš„ tensorflow-cpu ç‰ˆæœ¬ã€‚"

        model = load_model(model_path, custom_objects={'cox_ph_loss': cox_ph_loss})

        try:
            preproc = joblib.load(preproc_path)
        except ModuleNotFoundError as e:
            missing = str(e).split("'")[1] if "'" in str(e) else str(e)
            return None, None, f"âŒ è¼‰å…¥ preprocessor å¤±æ•—ï¼šç¼ºå°‘æ¨¡çµ„ {missing}ã€‚è«‹åœ¨ requirements.txt åŠ å…¥è©²å¥—ä»¶ï¼ˆä¾‹å¦‚ dillï¼‰ï¼Œä¸¦é‡æ–°éƒ¨ç½²ã€‚"
        except Exception as e:
            return None, None, f"âŒ è¼‰å…¥ preprocessor ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"

        return model, preproc, "âœ… æ¨¡å‹èˆ‡ Preprocessor è¼‰å…¥æˆåŠŸ (from upload)"
    except Exception as e:
        return None, None, f"âŒ è¼‰å…¥å¤±æ•—ï¼š{e}"
    finally:
        for p in (model_path, preproc_path):
            try:
                if p and os.path.exists(p):
                    os.remove(p)
            except Exception:
                pass

# -------------------------
# predict function
# -------------------------
def predict_once(model, preproc, input_data: dict):
    df = pd.DataFrame([input_data], columns=all_model_features)
    for col in continuous_vars:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    X = preproc.transform(df)
    risk_arr = model.predict(X, verbose=0)
    try:
        risk = float(risk_arr.reshape(-1)[0])
    except Exception:
        risk = float(risk_arr[0])
    return risk

# -------------------------
# UI: load mode selection
# -------------------------
st.title("ğŸ§® é¢¨éšªåˆ†æ•¸é æ¸¬å™¨ï¼ˆCox æ¨¡å‹ï¼‰")
st.write("æ”¯æ´ï¼š1) å¾ URL / GitHub Releases è‡ªå‹•ä¸‹è¼‰ model.h5 èˆ‡ preprocessor.pklï¼›2) æ‰‹å‹•ä¸Šå‚³æª”æ¡ˆï¼ˆfallbackï¼‰ã€‚")

mode = st.radio("è¼‰å…¥æ–¹å¼", ("å¾ URL / GitHub Releases ä¸‹è¼‰", "æ‰‹å‹•ä¸Šå‚³æª”æ¡ˆ (æœ¬åœ°)"))

# Load any existing model from session_state
model = st.session_state.get("model", None)
preproc = st.session_state.get("preproc", None)
load_msg = st.session_state.get("load_msg", "")

if st.button("æ¸…é™¤å·²è¼‰å…¥æ¨¡å‹"):
    st.session_state.pop("model", None)
    st.session_state.pop("preproc", None)
    st.session_state.pop("load_msg", None)
    model = preproc = None
    st.success("å·²æ¸…é™¤å·²è¼‰å…¥çš„æ¨¡å‹/Preprocessorã€‚")

if mode == "å¾ URL / GitHub Releases ä¸‹è¼‰":
    st.markdown("**æ–¹å¼ Aï¼šç›´æ¥è²¼å¯ä¸‹è¼‰çš„ MODEL_URL èˆ‡ PREPROC_URLï¼ˆå¯è²¼ blob URLï¼Œæœƒè‡ªå‹•è½‰æˆ rawï¼‰**")
    col1, col2 = st.columns(2)
    default_model_raw = convert_github_blob_to_raw(DEFAULT_MODEL_BLOB)
    default_preproc_raw = convert_github_blob_to_raw(DEFAULT_PREPROC_BLOB)
    with col1:
        model_url = st.text_input("MODEL_URL (æˆ–ç•™ç©ºä½¿ç”¨é è¨­)", value=st.secrets.get("MODEL_URL", default_model_raw))
    with col2:
        preproc_url = st.text_input("PREPROC_URL (æˆ–ç•™ç©ºä½¿ç”¨é è¨­)", value=st.secrets.get("PREPROC_URL", default_preproc_raw))

    st.markdown("---")
    st.markdown("**æ–¹å¼ Bï¼šå¾ GitHub Releases ä¸‹è¼‰ assetï¼ˆå¡«å¯« repo èˆ‡ asset åç¨±ï¼‰**")
    repo = st.text_input("GitHub repo (owner/repo)", value=st.secrets.get("GITHUB_REPO", ""))
    asset_model = st.text_input("Release asset name for model (e.g. model.h5)", value=st.secrets.get("MODEL_ASSET_NAME", ""))
    asset_preproc = st.text_input("Release asset name for preprocessor (e.g. preprocessor.pkl)", value=st.secrets.get("PREPROC_ASSET_NAME", ""))
    github_token = st.secrets.get("GITHUB_TOKEN", "")

    if st.button("ä¸‹è¼‰ä¸¦è¼‰å…¥ (å¾ URL/GitHub)"):
        try:
            final_model_url = None
            final_preproc_url = None
            token = github_token or None

            # Convert blob->raw if necessary
            if model_url:
                final_model_url = convert_github_blob_to_raw(model_url)
            if preproc_url:
                final_preproc_url = convert_github_blob_to_raw(preproc_url)

            if not (final_model_url and final_preproc_url):
                # try GitHub Releases route
                if repo and asset_model and asset_preproc:
                    try:
                        final_model_url = get_github_asset_browser_download_url(repo, asset_model, token=token)
                        final_preproc_url = get_github_asset_browser_download_url(repo, asset_preproc, token=token)
                    except Exception as e:
                        st.error(f"å¾ GitHub Releases å–å¾— asset URL å¤±æ•—ï¼š{e}")
                        final_model_url = final_preproc_url = None
                else:
                    st.error("è«‹æä¾›æœ‰æ•ˆçš„ MODEL_URL + PREPROC_URLï¼Œæˆ–å¡«å¯« repo èˆ‡ asset åç¨±ä»¥ä½¿ç”¨ GitHub Releasesã€‚")
                    final_model_url = final_preproc_url = None

            if final_model_url and final_preproc_url:
                with st.spinner("ä¸‹è¼‰ä¸¦è¼‰å…¥æ¨¡å‹èˆ‡ preprocessor...ï¼ˆå¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ï¼‰"):
                    model, preproc, load_msg = load_resources_from_urls(final_model_url, final_preproc_url, token=token)
                    if model is None or preproc is None:
                        st.error(load_msg)
                    else:
                        # Persist into session_state so next reruns can use them
                        st.session_state["model"] = model
                        st.session_state["preproc"] = preproc
                        st.session_state["load_msg"] = load_msg
                        st.success(load_msg)
        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

else:
    # Upload mode (manual)
    st.subheader("ä¸Šå‚³æœ¬åœ°æª”æ¡ˆ")
    col1, col2 = st.columns(2)
    with col1:
        uf_model = st.file_uploader("ä¸Šå‚³ model.h5", type=["h5"])
    with col2:
        uf_preproc = st.file_uploader("ä¸Šå‚³ preprocessor.pkl", type=["pkl"])

    if st.button("è¼‰å…¥ä¸Šå‚³çš„æ¨¡å‹èˆ‡ preprocessor"):
        if uf_model is None or uf_preproc is None:
            st.error("è«‹åŒæ™‚ä¸Šå‚³ model.h5 èˆ‡ preprocessor.pkl")
        else:
            try:
                uf_model.seek(0); uf_preproc.seek(0)
                mbytes = uf_model.read(); pbytes = uf_preproc.read()
                with st.spinner("è¼‰å…¥æ¨¡å‹èˆ‡ preprocessor..."):
                    model, preproc, load_msg = load_resources_from_bytes_local(mbytes, pbytes)
                    if model is None or preproc is None:
                        st.error(load_msg)
                    else:
                        st.session_state["model"] = model
                        st.session_state["preproc"] = preproc
                        st.session_state["load_msg"] = load_msg
                        st.success(load_msg)
            except Exception as e:
                st.error(f"è¼‰å…¥ä¸Šå‚³æª”æ¡ˆç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

# -------------------------
# Prediction form
# -------------------------
st.subheader("2. è¼¸å…¥ Features")
with st.form("prediction_form"):
    age = st.number_input("Age", value=60, step=1)
    ca199 = st.number_input("CA199", value=35.0, format="%.2f")
    size = st.number_input("Tumor Size (cm)", value=2.5, format="%.2f")

    sex = st.selectbox("Sex", sex_opts)
    grade = st.selectbox("Grade", grade_opts)
    margin = st.selectbox("Margin", yn_opts)
    LVI = st.selectbox("LVI", yn_opts)
    PNI = st.selectbox("PNI", yn_opts)
    pT = st.selectbox("pT", pT_opts)
    pN = st.selectbox("pN", pN_opts)
    cysticneoplasm = st.selectbox("Cystic Neoplasm", yn_opts)
    neoadjuvant = st.selectbox("Neoadjuvant", yn_opts)
    opmethod = st.selectbox("Surgical Method", op_opts)

    submitted = st.form_submit_button("è¨ˆç®— Risk Score")

    # Always read model/preproc from session_state at time of prediction
    model = st.session_state.get("model", None)
    preproc = st.session_state.get("preproc", None)

    if submitted:
        if model is None or preproc is None:
            st.warning("è«‹å…ˆè¼‰å…¥ä¸¦æˆåŠŸè¼‰å…¥æ¨¡å‹èˆ‡å‰è™•ç†å™¨ï¼ˆmodel.h5 èˆ‡ preprocessor.pklï¼‰ã€‚")
        else:
            input_data = {
                'age': age,
                'ca199': ca199,
                'size': size,
                'sex': sex,
                'grade': grade,
                'margin': margin,
                'LVI': LVI,
                'PNI': PNI,
                'pT': pT,
                'pN': pN,
                'cysticneoplasm': cysticneoplasm,
                'neoadjuvant': neoadjuvant,
                'opmethod': opmethod,
            }
            try:
                with st.spinner("è¨ˆç®—ä¸­..."):
                    score = predict_once(model, preproc, input_data)
                st.success(f"ğŸ’¡ é æ¸¬é¢¨éšªåˆ†æ•¸ï¼š`{score:.6f}`ï¼ˆåˆ†æ•¸è¶Šé«˜é¢¨éšªè¶Šé«˜ï¼‰")
            except Exception as e:
                st.error(f"é æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

# -------------------------
# Footer: tips & defaults
# -------------------------
st.markdown("---")
st.markdown("**éƒ¨ç½²æç¤º**ï¼š")
st.markdown(f"""
- é è¨­ raw URL (å·²ç”± blob è½‰æ›)ï¼š
  - MODEL: `{convert_github_blob_to_raw(DEFAULT_MODEL_BLOB)}`
  - PREPROC: `{convert_github_blob_to_raw(DEFAULT_PREPROC_BLOB)}`

- å¦‚æœ preprocessor ä½¿ç”¨åˆ° `dill` æˆ–å…¶å®ƒéæ¨™æº–æ¨¡çµ„ï¼Œè«‹åœ¨ `requirements.txt` åŠ å…¥è©²å¥—ä»¶ï¼ˆä¾‹å¦‚ `dill`ï¼‰ã€‚
- è‹¥ preprocessor æ˜¯ä½¿ç”¨ scikit-learn 1.6.1 ç”¢ç”Ÿï¼Œè«‹åœ¨ `requirements.txt` pin `scikit-learn==1.6.1`ã€‚
- è‹¥è¦åœ¨ Streamlit Cloud ç›´æ¥è¼‰å…¥ TF æ¨¡å‹ï¼Œè«‹åœ¨ `requirements.txt` pin ä¸€å€‹æ”¯æ´è©² Python ç‰ˆæœ¬çš„ TensorFlowï¼ˆä¾‹å¦‚ `tensorflow-cpu==2.20.0`ï¼Œè¦– cloud Python ç‰ˆæœ¬è€Œå®šï¼‰ã€‚
- **å®‰å…¨æé†’**ï¼šåƒ…è¼‰å…¥ä½ ä¿¡ä»»çš„ model.h5 / preprocessor.pklï¼Œå› ç‚ºååºåˆ—åŒ–å¯èƒ½åŸ·è¡Œä»»æ„ç¨‹å¼ç¢¼ã€‚
""")